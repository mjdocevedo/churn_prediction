| Concept MLflow | Module 1   | Module 2        | Module 3       |
| -------------- | ---------- | --------------- | -------------- |
| Run            | Exp√©rience | Pipeline        | Requ√™te        |
| Artefact       | Plot       | Docker / mod√®le | Prompt / trace |
| Version        | Hyperparam | Model Registry  | Prompt / agent |
| Comparaison    | Mod√®les    | Versions        | Comportements  |

# Module 1:  MLflow ‚Äì Introduction (pour tous, surtout Data Scientists)
Objectif : compr√©hension, rigueur exp√©rimentale, comparaison de mod√®les.

Contenu :
- Tracking des exp√©riences
- Logging des m√©triques
- Comparaison de runs
- Lecture et analyse de l‚ÄôUI


## Outline
1. NB1 
    - Pr√©senter MLflow globalement
    - Vid√©o Jerem
    - L'archi Mlflow : Tracking, Projects, Models, Model Registry.
        - Sur le usecase on approfondit Mlflow Tracking (parametres, metriques, plots) et MLflow Models (partiellement, comprendre le concept de l'artifact Logged Model, comprendre que MLflow sauvegarde le model pour pouvoir y revenir plus tard)
2. NB2
    - Clone du repo, pr√©sentation de l'achi minimale √† faire √©voluer
        ```bash
            churn_prediction/
            ‚îú‚îÄ‚îÄ .venv/
            ‚îú‚îÄ‚îÄ data/
            ‚îÇ   ‚îî‚îÄ‚îÄ telco_churn.csv
            ‚îú‚îÄ‚îÄ src/
            ‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py
            ‚îÇ   ‚îú‚îÄ‚îÄ loader.py
            ‚îÇ   ‚îú‚îÄ‚îÄ serve.py
            ‚îÇ   ‚îî‚îÄ‚îÄ train.py
            ‚îú‚îÄ‚îÄ .gitignore
            ‚îú‚îÄ‚îÄ Dockerfile
            ‚îú‚îÄ‚îÄ MLproject
            ‚îú‚îÄ‚îÄ pyproject.toml
            ‚îî‚îÄ‚îÄ README.md
        ```
    - Intro UV brievement, mise en place √† travers pyproject.toml.
    - Modifier `src/train.py` pour mettre en place MLFlow, puis lancer le script `uv run src/train.py`. √Ä evoquer : 
        * Qu'est-ce que c'est `mlruns` ? -> Artifact Store. Sauvegarde les fichiers (models, plots, requirements.txt) pour chaque run. C'est comme le "hard drive" des issus des exp√©riences. √Ä noter qu'en prod on le remplace par un S3/Blob/autre. (Approfondir dans le Module 2)
        * Qu'est ce que c'est `mlflow.db`? -> Backend Store (une base de donn√©es SQLite). Sauvegarde la metadonn√©e (metriques, param√®tres, nom des runs, tags). C'est comme l'indexe ou catalogue dont MLflow UI a besoin pour afficher les tableaux de runs.  √Ä noter qu'en prod on le remplace par PostgreSQL (Approfondir dans le Module 2)
    - Acc√©der au MLFlow UI √† travers la commande `uv run mlflow ui`
        * Expliquer que le port 5000 est le port d√©fini par d√©faut dans le module MLflow. Sauf explicit√© autrement, 127.0.0.1:5000.
        * Est-ce modifiable ? 
            1. Pour changer le port port: `-p` or `--port`. `uv run mlflow ui -p 5001`
            2. Pour changer le h√¥te: `-h` or `--host`. `uv run mlflow ui -h 0.0.0.0`
    - Une fois dans l'UI
        * Cliquer dans le Training_Run
        * Focus : montrer les param√®tres, la configuration utilis√©e.
        * On a r√©ussi √† capturer les exp√©riences, leur d√©finition et un mod√®le candidat.
    - Modifier `src/evaluate.py` pour mettre en place mlflow et faire une analyse de performance. Puis lancer le script `uv run src/evaluate.py`
        * Un nouveau run, cliquer dans Evaluate_Run.
        * Focus : approfondir sur les artifacts.
        * Des preuves visuelles, matrice de confusion, courbes. MLflow gen√®re des rapports de mani√®re automatique.

Key takeaway: training about creating the object, evaluation about understainding it.


# Module 2: MLflow ‚Äì Parcours MLOps (sp√©cialisation)
Objectif : industrialisation compl√®te du cycle de vie ML.

Contenu :
- MLflow Projects
- Int√©gration Docker
- Registry de mod√®les
- Promotion des versions
- D√©ploiement (API / serving)
- Interaction avec pipelines

Format :
- Module plus avanc√©, orient√© production
- Examen sp√©cialit√© :
- 1 repo fourni avec un pipeline existant
- Les apprenants doivent ex√©cuter des commandes MLflow, √©crire de petits scripts d‚Äôanalyse, retrouver des informations dans les runs / registry, puis r√©pondre √† un QCM bas√© sur leurs r√©sultats

# Module 3: MLflow ‚Äì Parcours LLMOps (sp√©cialisation)
Objectif : observabilit√©, tra√ßage et √©valuation de syst√®mes LLM / RAG / agents.

Contenu :
- Tracing MLflow
- Evaluation GenAI
- Prompt management
- Analyse de conversations
- Debug d‚Äôagents

Format :
- Module orient√© syst√®mes cognitifs
- Examen sp√©cialit√© :
- 1 repo fourni avec un agent + RAG + traces existantes
- Les apprenants doivent analyser les traces, comprendre les erreurs, investiguer les runs, et r√©pondre √† un QCM bas√© sur leur analyse




# Projet 
### Customer churn prediction 
Dataset : Telco Customer Churn (IBM)
* CSV public
* ~7k lignes
* Classification binaire
* Colonnes simples :
    * num√©riques
    * cat√©gorielles
* Label : Churn

#### MODULE 1 ‚Äì MLflow Introduction
Mod√®le
* Logistic Regression
* RandomForest (optionnel)

MLflow
* Tracking des exp√©riences
* Logging :
    * params (C, max_depth)
    * metrics (accuracy, roc_auc)
    * artefacts (ROC curve, confusion matrix)
üìå Tr√®s simple √† comprendre
üìå Aucun NLP, aucune feature complexe

#### MODULE 2 ‚Äì MLOps
Industrialisation naturelle
* MLflow Projects
* Docker
* Registry
* Promotion Staging ‚Üí Production
* Serving REST

Pipeline
train ‚Üí evaluate ‚Üí register ‚Üí serve

#### MODULE 3 ‚Äì LLMOps (optionnel / isol√©)
Mini use case LLMOps
* Analyse automatique de commentaires clients (autre CSV)
* LLM = outil d‚Äôobservabilit√© / analyse
* MLflow utilis√© pour :
    * tracing
    * √©valuation
    * prompt versioning
Aucun lien direct requis avec le churn.
